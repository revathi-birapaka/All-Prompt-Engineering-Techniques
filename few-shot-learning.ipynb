{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd12115-3a6b-4373-8593-1ed51b88d707",
   "metadata": {},
   "source": [
    "### Few-Shot Learning and In-Context Learning Tutorial\n",
    "#### Overview\n",
    "This tutorial explores the cutting-edge techniques of Few-Shot Learning and In-Context Learning using OpenAI's GPT models and the LangChain library. These methods enable AI models to perform complex tasks with minimal examples, revolutionizing the way we approach machine learning problems.\n",
    "\n",
    "#### Motivation\n",
    "Traditional machine learning often requires large datasets for training, which can be time-consuming and resource-intensive. Few-Shot Learning and In-Context Learning address this limitation by leveraging the power of large language models to perform tasks with just a handful of examples. This approach is particularly valuable in scenarios where labeled data is scarce or expensive to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ce000-616b-416c-8b7f-82f49c7aee85",
   "metadata": {},
   "source": [
    "### Method Details\n",
    "#### 1. Basic Few-Shot Learning\n",
    "Implementation of a sentiment classification task using few-shot learning.\n",
    "Demonstration of how to structure a prompt with examples for the model to learn from.\n",
    "Explanation of how the model generalizes from these examples to new inputs.\n",
    "#### 2. Advanced Few-Shot Techniques\n",
    "Exploration of multi-task learning for sentiment analysis and language detection.\n",
    "Discussion on how to design prompts that enable a single model to perform multiple related tasks.\n",
    "Insights into the benefits of this approach, such as improved efficiency and better generalization.\n",
    "#### 3. In-Context Learning\n",
    "Demonstration of in-context learning for a custom task (e.g., text transformation).\n",
    "Explanation of how models can adapt to new tasks based solely on examples provided in the prompt.\n",
    "Discussion on the flexibility and limitations of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e105795-2144-4fa8-8591-cfff13c2e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY') # OpenAI API key\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f03a8d-d6d7-413f-a2a5-be9fe7aea258",
   "metadata": {},
   "source": [
    "### Basic Few-Shot Learning\n",
    "We'll implement a basic few-shot learning scenario for sentiment classification.\n",
    "\n",
    "#### Sentiment Classification:\n",
    "\n",
    "Definition: Determining the emotional tone behind a series of words.\n",
    "Applications: Customer service, market research, social media analysis.\n",
    "Few-Shot Learning Approach:\n",
    "\n",
    "Provide a small set of labeled examples (3 in this case).\n",
    "Structure the prompt to clearly present examples and the new input.\n",
    "Leverage the pre-trained knowledge of the language model.\n",
    "#### Key Components:\n",
    "\n",
    "PromptTemplate: Structures the input for the model.\n",
    "LLMChain: Manages the interaction between the prompt and the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00364d2-a769-4bbb-8232-33d8832f556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I can't believe how great this new restaurant is!\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def few_shot_sentiment_classification(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Classify the sentiment as Positive, Negative, or Neutral.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Sentiment: Positive\n",
    "        \n",
    "        Text: This movie was terrible. I hated it.\n",
    "        Sentiment: Negative\n",
    "        \n",
    "        Text: The weather today is okay.\n",
    "        Sentiment: Neutral\n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    # Clean up the result\n",
    "    result = result.strip()\n",
    "    # Extract only the sentiment label\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  # This will now return just \"Positive\", \"Negative\", or \"Neutral\"\n",
    "\n",
    "test_text = \"I can't believe how great this new restaurant is!\"\n",
    "result = few_shot_sentiment_classification(test_text)\n",
    "print(f\"Input: {test_text}\")\n",
    "print(f\"Predicted Sentiment: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9092d-4521-410f-8279-e1666eba0522",
   "metadata": {},
   "source": [
    "### Advanced Few-Shot Techniques\n",
    "We'll now explore multi-task learning for sentiment analysis and language detection.\n",
    "\n",
    "#### Multi-task Learning:\n",
    "\n",
    "Definition: Training a model to perform multiple related tasks simultaneously.\n",
    "Benefits: Improved efficiency, better generalization, reduced overfitting.\n",
    "#### Implementation:\n",
    "\n",
    "Design a prompt template that includes examples for multiple tasks.\n",
    "Use task-specific instructions to guide the model's behavior.\n",
    "Demonstrate how the same model can switch between tasks based on input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31af6a82-e852-4384-84be-d0864e495a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Result: German\n"
     ]
    }
   ],
   "source": [
    "def multi_task_few_shot(input_text, task):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\", \"task\"],\n",
    "        template=\"\"\"\n",
    "        Perform the specified task on the given text.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Task: sentiment\n",
    "        Result: Positive\n",
    "        \n",
    "        Text: Bonjour, comment allez-vous?\n",
    "        Task: language\n",
    "        Result: French\n",
    "        \n",
    "        Now, perform the following task:\n",
    "        Text: {input_text}\n",
    "        Task: {task}\n",
    "        Result:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    return chain.invoke({\"input_text\": input_text, \"task\": task}).content\n",
    "\n",
    "print(multi_task_few_shot(\"I can't believe how great this is!\", \"sentiment\"))\n",
    "print(multi_task_few_shot(\"Guten Tag, wie geht es Ihnen?\", \"language\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d2890-20ca-4171-8fdb-a8014528b436",
   "metadata": {},
   "source": [
    "### In-Context Learning\n",
    "In-Context Learning allows models to adapt to new tasks based on examples provided in the prompt.\n",
    "\n",
    "#### Key Aspects:\n",
    "\n",
    "No fine-tuning required: The model learns from examples in the prompt.\n",
    "#### Flexibility: Can be applied to a wide range of tasks.\n",
    "Prompt engineering: Careful design of prompts is crucial for performance.\n",
    "Example Implementation: We'll demonstrate in-context learning for a custom task (converting text to pig latin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82049cfb-eec4-4587-8f8f-bc345a233621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: python\n",
      "Output: Output: ythonpay\n"
     ]
    }
   ],
   "source": [
    "def in_context_learning(task_description, examples, input_text):\n",
    "    example_text = \"\".join([f\"Input: {e['input']}\\nOutput: {e['output']}\\n\\n\" for e in examples])\n",
    "    \n",
    "    in_context_prompt = PromptTemplate(\n",
    "        input_variables=[\"task_description\", \"examples\", \"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Task: {task_description}\n",
    "        \n",
    "        Examples:\n",
    "        {examples}\n",
    "        \n",
    "        Now, perform the task on the following input:\n",
    "        Input: {input_text}\n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = in_context_prompt | llm\n",
    "    return chain.invoke({\"task_description\": task_description, \"examples\": example_text, \"input_text\": input_text}).content\n",
    "\n",
    "task_desc = \"Convert the given text to pig latin.\"\n",
    "examples = [\n",
    "    {\"input\": \"hello\", \"output\": \"ellohay\"},\n",
    "    {\"input\": \"apple\", \"output\": \"appleay\"}\n",
    "]\n",
    "test_input = \"python\"\n",
    "\n",
    "result = in_context_learning(task_desc, examples, test_input)\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e014cbea-925f-4544-8df2-71ccf187fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This product exceeded my expectations!\n",
      "Predicted: Positive\n",
      "Actual: Positive\n",
      "Correct: True\n",
      "\n",
      "Input: I'm utterly disappointed with the service.\n",
      "Predicted: Negative\n",
      "Actual: Negative\n",
      "Correct: True\n",
      "\n",
      "Input: The temperature today is 72 degrees.\n",
      "Predicted: Neutral\n",
      "Actual: Neutral\n",
      "Correct: True\n",
      "\n",
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_func, test_cases):\n",
    "    '''\n",
    "    Evaluate the model on a set of test cases.\n",
    "\n",
    "    Args:\n",
    "    model_func: The function that makes predictions.\n",
    "    test_cases: A list of dictionaries, where each dictionary contains an \"input\" text and a \"label\" for the input.\n",
    "\n",
    "    Returns:\n",
    "    The accuracy of the model on the test cases. \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "    \n",
    "    for case in test_cases:\n",
    "        input_text = case['input']\n",
    "        true_label = case['label']\n",
    "        prediction = model_func(input_text).strip()\n",
    "        \n",
    "        is_correct = prediction.lower() == true_label.lower()\n",
    "        correct += int(is_correct)\n",
    "        \n",
    "        print(f\"Input: {input_text}\")\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "        print(f\"Actual: {true_label}\")\n",
    "        print(f\"Correct: {is_correct}\\n\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_cases = [\n",
    "    {\"input\": \"This product exceeded my expectations!\", \"label\": \"Positive\"},\n",
    "    {\"input\": \"I'm utterly disappointed with the service.\", \"label\": \"Negative\"},\n",
    "    {\"input\": \"The temperature today is 72 degrees.\", \"label\": \"Neutral\"}\n",
    "]\n",
    "\n",
    "accuracy = evaluate_model(few_shot_sentiment_classification, test_cases)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d44442-bc56-4add-8204-9b517173cf09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
