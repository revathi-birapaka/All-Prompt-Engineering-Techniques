{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579898ab",
   "metadata": {},
   "source": [
    "# Tree-of-Thought (ToT) Prompting in Jupyter\n",
    "This notebook demonstrates Tree-of-Thought reasoning with search strategies.\n",
    "It runs standalone with a MockLLM but can be connected to OpenAI/OpenRouter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ce14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from typing import List, Tuple, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a334ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLLM:\n",
    "    \"\"\"A deterministic mock LLM for offline testing.\"\"\"\n",
    "    def __init__(self, seed:int=42):\n",
    "        random.seed(seed)\n",
    "\n",
    "    def generate(self, prompt:str, n:int=1) -> List[str]:\n",
    "        base = \"Thought based on: \" + prompt.split(\"\\n\")[-1][:30]\n",
    "        return [f\"{base} [Option {i}]\" for i in range(1, n+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e009bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTNode:\n",
    "    def __init__(self, state:str, parent:Optional['ToTNode']=None, depth:int=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.depth = depth\n",
    "        self.children: List[ToTNode] = []\n",
    "        self.score: float = 0.0\n",
    "\n",
    "    def path(self) -> List[str]:\n",
    "        node, path = self, []\n",
    "        while node:\n",
    "            path.append(node.state)\n",
    "            node = node.parent\n",
    "        return path[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1263378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_of_thought_search(prompt:str, llm, max_depth:int=3, beam_width:int=2):\n",
    "    root = ToTNode(prompt, parent=None, depth=0)\n",
    "    frontier = [root]\n",
    "\n",
    "    for depth in range(max_depth):\n",
    "        new_frontier = []\n",
    "        for node in frontier:\n",
    "            thoughts = llm.generate(node.state, n=beam_width)\n",
    "            for t in thoughts:\n",
    "                child = ToTNode(t, parent=node, depth=depth+1)\n",
    "                child.score = random.random()  # heuristic scoring\n",
    "                node.children.append(child)\n",
    "                new_frontier.append(child)\n",
    "        frontier = sorted(new_frontier, key=lambda x: -x.score)[:beam_width]\n",
    "\n",
    "    return frontier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43213b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: How can we reduce traffic in cities? -> Thought based on: How can we reduce traffic in c [Option 2] -> Thought based on: Thought based on: How can we r [Option 1] -> Thought based on: Thought based on: Thought base [Option 1]\n",
      "Score: 0.8921795677048454 \n",
      "\n",
      "Path: How can we reduce traffic in cities? -> Thought based on: How can we reduce traffic in c [Option 2] -> Thought based on: Thought based on: How can we r [Option 2] -> Thought based on: Thought based on: Thought base [Option 1]\n",
      "Score: 0.4219218196852704 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = MockLLM()\n",
    "final_nodes = tree_of_thought_search(\"How can we reduce traffic in cities?\", llm)\n",
    "\n",
    "for node in final_nodes:\n",
    "    print(\"Path:\", \" -> \".join(node.path()))\n",
    "    print(\"Score:\", node.score, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd20a34-6bfd-40ef-85f6-cf4ea9d60004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
